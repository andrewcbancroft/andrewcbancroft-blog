---
title: Piecing Together the Components of the Hadoop Ecosystem
excerpt: "The list of software components and in the Hadoop ecosystem may be long, but each component exists with a purpose. Discover more about the kinds of problem each component solves."
layout: work-in-progress
toc: true
categories: [Big Data, Hadoop]
---

While it's true that originally, "Hadoop" referred primarily to a distributed file system (HDFS), a resource manager (YARN), and a programming model for processing data (MapReduce), years of adoption and use have led to an outpouring of community contributions in the form of (mostly) open source projects and frameworks.

Today, "Hadoop" is best thought of as a *composition* of the three core components (HDFS, YARN, and MapReduce), and a selection of the  various frameworks that have been designed to do what frameworks are *supposed* to do: To provide you higher-level way to interact with some of the lower-level components... to ease tedious tasks... to provide new, more efficient processing mechanisms over some of the core technologies... to extend the functionality of the base components, etc.

